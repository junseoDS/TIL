{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. (02/26)오존 파일(Ozone.csv)을 이용하여 linear regression 구현\n",
    "   \n",
    "   tensorflow, python, sklearn으로 구현하고 결과를 비교해보아요!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp</th>\n",
       "      <th>Ozone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.397849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.344086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.086022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.150538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.107527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.279570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.107527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.150538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.172043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Temp     Ozone\n",
       "0    0.181818  0.397849\n",
       "1    0.333333  0.344086\n",
       "2    0.393939  0.086022\n",
       "3    0.030303  0.150538\n",
       "5    0.151515  0.258065\n",
       "..        ...       ...\n",
       "147  0.060606  0.107527\n",
       "148  0.272727  0.279570\n",
       "150  0.424242  0.107527\n",
       "151  0.454545  0.150538\n",
       "152  0.212121  0.172043\n",
       "\n",
       "[103 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W : [[0.24539252]], b : [-1.059275], loss : 1.713784098625183\n",
      "W : [[0.78947127]], b : [-0.04603548], loss : 0.0303288996219635\n",
      "W : [[0.7913756]], b : [-0.04636393], loss : 0.030327588319778442\n",
      "W : [[0.7921335]], b : [-0.04684763], loss : 0.030327273532748222\n",
      "W : [[0.7923606]], b : [-0.04699255], loss : 0.030327199026942253\n",
      "W : [[0.7923789]], b : [-0.04700424], loss : 0.030327193439006805\n",
      "W : [[0.7923789]], b : [-0.04700424], loss : 0.030327193439006805\n",
      "W : [[0.7923789]], b : [-0.04700424], loss : 0.030327193439006805\n",
      "W : [[0.7923789]], b : [-0.04700424], loss : 0.030327193439006805\n",
      "W : [[0.7923789]], b : [-0.04700424], loss : 0.030327193439006805\n"
     ]
    }
   ],
   "source": [
    "# 온도에 따른 Ozone량 예측\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats     # 이상치 처리를 위해서 필요\n",
    "import tensorflow as tf     # tensorflow 구현\n",
    "from sklearn import linear_model  # sklearn으로 simple linear regression 구현\n",
    "from sklearn.preprocessing import MinMaxScaler # normalization 전처리\n",
    "\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('data/ozone.csv')\n",
    "training_data = df[['Temp','Ozone']]   # 153 rows × 2 columns\n",
    "\n",
    "# 결측치부터 처리해 보아요!\n",
    "# 결측치를 찾아서 제거할꺼예요!\n",
    "training_data = training_data.dropna(how='any')\n",
    "# display(training_data)    # 116 rows × 2 columns\n",
    "\n",
    "# 이상치 처리(outlier)\n",
    "# z-score를 이용해서 outlier를 처리\n",
    "zscore_threshold = 1.8\n",
    "\n",
    "# Temp에 대한 outlier(지대점)\n",
    "tmp = ~(np.abs(stats.zscore(training_data['Temp'])) > zscore_threshold)\n",
    "training_data = training_data.loc[tmp]\n",
    "# display(training_data)   # 110 rows × 2 columns\n",
    "\n",
    "# Ozone에 대한 outlier\n",
    "tmp = ~(np.abs(stats.zscore(training_data['Ozone'])) > zscore_threshold)\n",
    "training_data = training_data.loc[tmp]\n",
    "# display(training_data)   # 103 rows × 2 columns\n",
    "\n",
    "###########################\n",
    "# 정규화 처리를 진행(Min-Max Scaler)\n",
    "# 직접구현해도 되지만 sklearn을 이용해서 처리해 보아요!\n",
    "\n",
    "# Min-Max Scaler라고 불리는 객체를 생성\n",
    "# 이 객체를 두개 만들꺼예요! 독립변수와 종속변수에 대해서 각각 만들어줘요!\n",
    "scaler_x = MinMaxScaler()  # 객체 생성\n",
    "scaler_t = MinMaxScaler()  # 객체 생성\n",
    "scaler_x.fit(training_data['Temp'].values.reshape(-1,1))\n",
    "scaler_t.fit(training_data['Ozone'].values.reshape(-1,1))\n",
    "# print(scaler_x.n_samples_seen_, scaler_x.data_max_, \n",
    "#       scaler_x.data_min_, scaler_x.feature_range)\n",
    "training_data['Temp'] = scaler_x.transform(training_data['Temp'].values.reshape(-1,1))\n",
    "training_data['Ozone'] = scaler_t.transform(training_data['Ozone'].values.reshape(-1,1))\n",
    "\n",
    "display(training_data)\n",
    "\n",
    "\n",
    "# Training Data Set\n",
    "x_data = training_data['Temp'].values.reshape(-1,1)\n",
    "t_data = training_data['Ozone'].values.reshape(-1,1)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([1,1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "H = tf.matmul(X,W) + b\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.square(H-T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(300000):\n",
    "    _, W_val, b_val, loss_val = sess.run([train, W, b, loss], \n",
    "                                         feed_dict={X: x_data, T: t_data})\n",
    "    \n",
    "    if step % 30000 == 0:\n",
    "        print('W : {}, b : {}, loss : {}'.format(W_val,b_val,loss_val))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W : [[0.79468511]], b : [-0.04818192]\n"
     ]
    }
   ],
   "source": [
    "# sklearn을 이용해서 구현해 보아요!\n",
    "# Training Data Set\n",
    "x_data = training_data['Temp'].values.reshape(-1,1)\n",
    "t_data = training_data['Ozone'].values.reshape(-1,1)\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x_data,t_data)\n",
    "\n",
    "print('W : {}, b : {}'.format(model.coef_, model.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (03/04) Kaggle Titanic Logistic Regression 구현\n",
    "\n",
    "=> 데이터 전처리\n",
    "\n",
    "=> 모델 구현\n",
    "\n",
    "=> 결과 파일 생성 후 Kaggle에 upload\n",
    "\n",
    "=> 모델 accuracy 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\data_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W:[[-0.808475  ]\n",
      " [ 0.9645169 ]\n",
      " [-0.21189117]\n",
      " [ 0.0066978 ]\n",
      " [-0.75339234]], b:[-0.33411357]. loss:1.023154616355896\n",
      "W:[[-0.39826816]\n",
      " [ 1.2994037 ]\n",
      " [ 0.06199502]\n",
      " [ 0.15035295]\n",
      " [-0.18584614]], b:[-0.08782816]. loss:0.5221495628356934\n",
      "W:[[-0.456008  ]\n",
      " [ 1.4759088 ]\n",
      " [-0.0046856 ]\n",
      " [ 0.19681007]\n",
      " [-0.04697669]], b:[-0.05631738]. loss:0.5004604458808899\n",
      "W:[[-0.49139068]\n",
      " [ 1.621526  ]\n",
      " [-0.04017282]\n",
      " [ 0.23680292]\n",
      " [-0.0199655 ]], b:[-0.02087574]. loss:0.4912562072277069\n",
      "W:[[-0.5162188 ]\n",
      " [ 1.7463461 ]\n",
      " [-0.06575611]\n",
      " [ 0.26780596]\n",
      " [-0.02053632]], b:[0.01529971]. loss:0.4848634898662567\n",
      "W:[[-0.5358467 ]\n",
      " [ 1.8545918 ]\n",
      " [-0.08795487]\n",
      " [ 0.29096842]\n",
      " [-0.02750851]], b:[0.05088053]. loss:0.4800356328487396\n",
      "W:[[-0.5524543 ]\n",
      " [ 1.9491807 ]\n",
      " [-0.10836962]\n",
      " [ 0.30810636]\n",
      " [-0.03571239]], b:[0.08564062]. loss:0.4762921929359436\n",
      "W:[[-0.56666607]\n",
      " [ 2.0316927 ]\n",
      " [-0.12738077]\n",
      " [ 0.32071495]\n",
      " [-0.04382223]], b:[0.11969041]. loss:0.4733527600765228\n",
      "W:[[-0.5793118 ]\n",
      " [ 2.1052208 ]\n",
      " [-0.14527448]\n",
      " [ 0.3299795 ]\n",
      " [-0.05157493]], b:[0.15298842]. loss:0.4709760546684265\n",
      "W:[[-0.5903805 ]\n",
      " [ 2.1701665 ]\n",
      " [-0.16218376]\n",
      " [ 0.33674932]\n",
      " [-0.05889071]], b:[0.1856429]. loss:0.4690474271774292\n"
     ]
    }
   ],
   "source": [
    "# Titanic 구현\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('data/titanic/train.csv')\n",
    "\n",
    "# 학습에 필요하지 않은 column은 삭제할 꺼예요!\n",
    "df.drop(['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin'], \n",
    "        axis=1, \n",
    "        inplace=True)\n",
    "# display(df)\n",
    "\n",
    "# 성별처리\n",
    "gender_mapping = {'male': 0, 'female': 1}\n",
    "df['Sex'] = df['Sex'].map(gender_mapping)\n",
    "\n",
    "# 가족처리\n",
    "df['Family'] = df['SibSp'] + df['Parch']\n",
    "df.drop(['SibSp', 'Parch'], axis=1, inplace=True)\n",
    "# display(df)\n",
    "\n",
    "# 결측치 처리\n",
    "# df.isnull().sum()\n",
    "# Embarked 결측치 처리\n",
    "df['Embarked'] = df['Embarked'].fillna('Q')\n",
    "# Embarked 문자를 숫자로 변환\n",
    "embarked_mapping = {'S': 0, 'C': 1, 'Q':2 }\n",
    "df['Embarked'] = df['Embarked'].map(embarked_mapping)\n",
    "\n",
    "# Age 결측치 처리\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "# Age Binning 처리(Numerical value -> Categorical value)\n",
    "df.loc[df['Age'] < 8,'Age'] = 0\n",
    "df.loc[(df['Age'] >= 8) & (df['Age'] < 20),'Age'] = 1\n",
    "df.loc[(df['Age'] >= 20) & (df['Age'] < 65),'Age'] = 2\n",
    "df.loc[df['Age'] >= 65,'Age'] = 3\n",
    "\n",
    "# display(df.shape)\n",
    "\n",
    "# 학습과 validation을 수행해야 해요!\n",
    "# 데이터를 7:3 비율로 Training Data Set과 Validation Data Set으로 분리\n",
    "train_data = df.iloc[:int(df.shape[0] * 0.7)]\n",
    "val_data = df.iloc[int(df.shape[0] * 0.7):]\n",
    "\n",
    "# Training Data Set\n",
    "train_x_data = train_data.drop(['Survived'], axis=1, inplace=False).values\n",
    "train_t_data = train_data['Survived'].values.reshape(-1,1)\n",
    "\n",
    "# Validation Data Set\n",
    "val_x_data = val_data.drop(['Survived'], axis=1, inplace=False).values\n",
    "val_t_data = val_data['Survived'].values.reshape(-1,1)\n",
    "\n",
    "#######################\n",
    "\n",
    "# Tensorflow 구현\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,5], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weigth & bias\n",
    "W = tf.Variable(tf.random.normal([5,1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                              labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "\n",
    "# session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(300000):\n",
    "    _, W_val, b_val, loss_val = sess.run([train,W,b,loss], \n",
    "                                         feed_dict={X: train_x_data,\n",
    "                                                    T: train_t_data})\n",
    "    if step % 30000 == 0:\n",
    "        print('W:{}, b:{}. loss:{}'.format(W_val,b_val,loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 정확도 : 0.7947761416435242\n"
     ]
    }
   ],
   "source": [
    "# 정확도(Accuracy) 측정\n",
    "predict = tf.cast(H > 0.5, dtype=tf.float32)  # 예측값 : [1 0 0 0 1 0 1 0]\n",
    "correct = tf.equal(predict, T) # T : [1 1 0 0 ..]   =>  [True, False, ...]  \n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "accuracy_val = sess.run(accuracy, feed_dict={X:val_x_data,\n",
    "                                             T:val_t_data})\n",
    "print('모델의 정확도 : {}'.format(accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. (03/08) BMI 데이터를 이용해서 모델 구현과 평가를 진행\n",
    "\n",
    "=> 데이터 전처리 \n",
    "\n",
    "=> 모델 구현\n",
    "\n",
    "=> K-Fold Cross Validation을 이용해서 모델 검증\n",
    "\n",
    "=> 우리모델의 최종 정확도를 출력!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Classification\n",
    "# %reset\n",
    "\n",
    "# Tensorflow로 구현해 보아요!\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('data/bmi.csv')\n",
    "\n",
    "# display(df.head(), df.shape)\n",
    "\n",
    "### 결측치 처리 ###\n",
    "# df.isnull().sum()   # 결측치가 존재하지 않아요!\n",
    "\n",
    "### 이상치 처리 ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['label']=='thin']=0\n",
    "df[df['label']=='normal']=1\n",
    "df[df['label']=='fat']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig_1 = fig.add_subplot(1,3,1)\n",
    "fig_2 = fig.add_subplot(1,3,2)\n",
    "fig_3 = fig.add_subplot(1,3,3)\n",
    "\n",
    "fig_1.boxplot(df['label'])\n",
    "fig_2.boxplot(df['height'])\n",
    "fig_3.boxplot(df['weight'])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### boxplot을 이용해서 이상치가 존재하는지를 확인해요!!\n",
    "### 이상치는 현재 존재하지 않아요!\n",
    "\n",
    "### Training Data Set\n",
    "x_data = df[['height', 'weight']].values\n",
    "t_data = df['label'].values  # one hot encoding으로 변환\n",
    "###      [0 1 2 0 1 1 2 2 0 1]\n",
    "###      [[1 0 0]\n",
    "###       [0 1 0]\n",
    "###       [0 0 1]\n",
    "###       [1 0 0]]\n",
    "\n",
    "### 정규화\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(x_data)\n",
    "norm_x_data = scaler_x.transform(x_data)\n",
    "# print(norm_x_data)\n",
    "\n",
    "### tensorflow 기능을 이용해서 one hot encoding을 생성\n",
    "sess = tf.Session()\n",
    "norm_t_data = sess.run(tf.one_hot(t_data, depth=3))\n",
    "# print(norm_t_data)\n",
    "\n",
    "## training data set 준비 끝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W : [[-0.38420066 -3.1364446   0.01314617]\n",
      " [ 0.84687424  0.04348576  1.8217024 ]], b: [0.10387253 0.16797481 2.005278  ], loss: 2.0013582706451416\n",
      "W : [[-0.3924109  -3.0935292  -0.02178626]\n",
      " [ 0.8386629   0.08662871  1.7867664 ]], b: [0.17725211 0.24156415 1.8583152 ], loss: 1.8723585605621338\n",
      "W : [[-0.40279135 -3.0506139  -0.05429058]\n",
      " [ 0.82828283  0.12951325  1.7542666 ]], b: [0.24564365 0.31253797 1.7189425 ], loss: 1.7551722526550293\n",
      "W : [[-0.415611   -3.0080388  -0.08403461]\n",
      " [ 0.81546265  0.17207682  1.7245232 ]], b: [0.3086656 0.3807098 1.5877506], loss: 1.649963617324829\n",
      "W : [[-0.43105644 -2.9658387  -0.11076275]\n",
      " [ 0.8000172   0.21425103  1.6977924 ]], b: [0.36611998 0.44594136 1.4650673 ], loss: 1.5563455820083618\n",
      "W : [[-0.44920632 -2.9241846  -0.13432272]\n",
      " [ 0.7818672   0.25595945  1.674232  ]], b: [0.4180119  0.50813556 1.3509821 ], loss: 1.4735628366470337\n",
      "W : [[-0.4700209  -2.883002   -0.15467724]\n",
      " [ 0.7610534   0.29712778  1.653876  ]], b: [0.46454751 0.5672362  1.2453451 ], loss: 1.4005026817321777\n",
      "W : [[-0.4933508  -2.84244    -0.17189647]\n",
      " [ 0.7377226   0.33767712  1.6366613 ]], b: [0.5061084 0.6232142 1.1478071], loss: 1.3359827995300293\n",
      "W : [[-0.5189604  -2.802595   -0.18613747]\n",
      " [ 0.7121145   0.37752694  1.6224203 ]], b: [0.5431902 0.676065  1.0578749], loss: 1.2787891626358032\n",
      "W : [[-0.54655033 -2.7635357  -0.19761522]\n",
      " [ 0.6845246   0.41659424  1.6109382 ]], b: [0.5763655  0.72579014 0.97497684], loss: 1.2278183698654175\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## tensorflow 구현\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([2,3]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([3]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit)   # Softmax Activation function 이용\n",
    "\n",
    "# loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                 labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "\n",
    "# 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습진행\n",
    "for step in range(30000):\n",
    "    _, W_val, b_val, loss_val = sess.run([train,W,b,loss], \n",
    "                                         feed_dict={X:norm_x_data,\n",
    "                                                    T:norm_t_data})\n",
    "    if step % 3000 == 0:\n",
    "        print('W : {}, b: {}, loss: {}'.format(W_val, b_val, loss_val))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.012269e-32 0.000000e+00 1.000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# 잘 만들어진 모델인지 확인하고 넘어가야 해요!(train, validation)\n",
    "\n",
    "# prediction\n",
    "height = 187\n",
    "weight = 78\n",
    "my_state = [[height, weight]]\n",
    "\n",
    "result = sess.run(H, feed_dict={X:scaler_x.transform(my_state)})\n",
    "print(result)  # 2 => 과체중 ?? 확인을 해 봐야 해요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 학습 시작 ###\n",
      "Loss : 0.48334065079689026\n",
      "Loss : 0.01813264936208725\n",
      "Loss : 0.008989641442894936\n",
      "Loss : 0.005963189527392387\n",
      "Loss : 0.004458380863070488\n",
      "Loss : 0.0035590233746916056\n",
      "Loss : 0.0029610388446599245\n",
      "Loss : 0.0025349638890475035\n",
      "Loss : 0.002215875778347254\n",
      "Loss : 0.001968128141015768\n",
      "### 학습 종료 ###\n",
      "### Training Data Set을 이용하여 성능평가! - 좋지 않아요! ###\n",
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Classification\n",
    "# BMI 예제\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler       # Normalization\n",
    "from sklearn.model_selection import train_test_split # train, test 분리\n",
    "from sklearn.model_selection import KFold            # Cross Validation\n",
    "\n",
    "# test data set은 우리 모델의 최종 accuracy를 측정하기 위해서 사용\n",
    "# train data set은 K-Fold Cross validation을 이용해서 내부적인 평가를 진행\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('data/bmi.csv')\n",
    "# display(df.head(),df.shape)\n",
    "\n",
    "df[df['label']=='thin']=0\n",
    "df[df['label']=='normal']=1\n",
    "df[df['label']=='fat']=2\n",
    "# 상관분석\n",
    "# 종속변수(레이블)에 영향을 미치지 않는 feature(속성, 필드)를 제외하기 위해서.\n",
    "# -1 ~ 1 사이의 실수값이 나와요! pandas를 이용해서 처리를 하면 되요!\n",
    "# 필요치 않은 column을 제거해요!\n",
    "\n",
    "# 결측치 처리\n",
    "# NaN이 있는지를 확인\n",
    "# df.isnull() : DataFrame안의 NaN에 대한 boolean mask를 생성(NaN이면 True)\n",
    "# 만약 결측치가 있으면 다른 값으로 대체할 필요가 있어요! => KNN으로 처리해보아요!\n",
    "# df.isnull().sum()\n",
    "\n",
    "# 이상치(outlier)\n",
    "# boxplot과 같은 graph를 이용해서 눈으로 확인!\n",
    "# turkey fense나 z-score방식으로 이상치를 찾아내고 처리하면 되요!\n",
    "# 우리예제는 이상치도 존재하지 않아요!\n",
    "\n",
    "# Data Split ( Train Data와 Test Data로 나눌꺼예요! )\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(df[['height', 'weight']],df['label'], \n",
    "                 test_size=0.3, \n",
    "                 random_state=0)  # random_state는 seed의 개념과 같아요!\n",
    "\n",
    "# Min-Max Scaler를 이용해서 정규화(Normalization)진행\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data_train)\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "\n",
    "# 혼동을 줄이기 위해 변수 삭제\n",
    "del x_data_train\n",
    "del x_data_test\n",
    "\n",
    "# Tensorflow 구현\n",
    "sess = tf.Session()\n",
    "t_data_train_onehot = sess.run(tf.one_hot(t_data_train, depth=3))\n",
    "t_data_test_onehot = sess.run(tf.one_hot(t_data_test, depth=3))\n",
    "\n",
    "del t_data_train\n",
    "del t_data_test\n",
    "\n",
    "# print(t_data_train_onehot)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([2,3]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([3]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit)  # softmax activation function\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                 labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "\n",
    "# parameter\n",
    "num_of_epoch = 1000\n",
    "batch_size = 100\n",
    "\n",
    "# 학습용 함수\n",
    "def run_train(sess,train_x, train_t):\n",
    "    print('### 학습 시작 ###')\n",
    "    # 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(num_of_epoch):\n",
    "        total_batch = int(train_x.shape[0] / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_t = train_t[i*batch_size:(i+1)*batch_size]           \n",
    "            _, loss_val = sess.run([train,loss],\n",
    "                                   feed_dict={X: batch_x,\n",
    "                                              T: batch_t})\n",
    "            \n",
    "        if step % 100 == 0:\n",
    "            print('Loss : {}'.format(loss_val))\n",
    "    print('### 학습 종료 ###')\n",
    "    \n",
    "# Accuracy 측정(정확도)    \n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(T,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "# 학습부터 해요!\n",
    "run_train(sess,x_data_train_norm, t_data_train_onehot)\n",
    "# Training Data Set을 이용하여 성능평가!\n",
    "print('### Training Data Set을 이용하여 성능평가! - 좋지 않아요! ###')\n",
    "result = sess.run(accuracy, feed_dict={X:x_data_train_norm,\n",
    "                                       T:t_data_train_onehot})\n",
    "print('Accuracy : {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (03/09) MNIST 데이터를 이용하여 모델 구현과 평가 진행\n",
    "\n",
    "    + 직접 손글씨로 쓴 예측용 데이터 생성 후 Prediction\n",
    "    \n",
    "    - 데이터는 Kaggle\n",
    "    - Multiclass Classification\n",
    "    - K-Fold Cross Validation\n",
    "    - 우리 모델의 최종 정확도\n",
    "    - 제출 파일 생성\n",
    "    - 직접 쓴 손글씨씨로 예측용 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 학습 시작 ###\n",
      "Loss : 1.9516072273254395\n",
      "Loss : 0.23559331893920898\n",
      "Loss : 0.18293681740760803\n",
      "Loss : 0.16185049712657928\n"
     ]
    }
   ],
   "source": [
    "# MNIST 구현\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('data/mnist/train.csv')\n",
    "# display(df.head(), df.shape)\n",
    "\n",
    "# 데이터의 명세를 잘 파악해야 해요!\n",
    "# 각 픽셀의 값은 0 ~ 255 사이의 값을 가질 수 있어요!\n",
    "# 이 값이 크면 클수록 어두운 색상이예요!\n",
    "\n",
    "# 결측치와 이상치를 처리해보아요! \n",
    "# => 현재 데이터에는 이상치와 결측치가 없어요!\n",
    "\n",
    "# 이미지 확인\n",
    "img_data = df.drop('label', axis=1, inplace=False).values\n",
    "\n",
    "fig = plt.figure()\n",
    "fig_arr = []   # 10개의 subplot을 만들고 그 각각의 subplot을 list에 저장\n",
    "\n",
    "for n in range(10):\n",
    "    fig_arr.append(fig.add_subplot(2,5,n+1))\n",
    "    fig_arr[n].imshow(img_data[n].reshape(28,28),\n",
    "                     cmap='Greys',\n",
    "                     interpolation='nearest')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 데이터 분할\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(df.drop('label', axis=1, inplace=False),\n",
    "                df['label'],\n",
    "                test_size=0.3,\n",
    "                random_state=0)\n",
    "\n",
    "# 정규화 작업!\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data_train)\n",
    "\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "\n",
    "# Tensorflow 구현\n",
    "sess = tf.Session()\n",
    "t_data_train_onehot = sess.run(tf.one_hot(t_data_train, depth=10))\n",
    "t_data_test_onehot = sess.run(tf.one_hot(t_data_test, depth=10))\n",
    "\n",
    "# sklearn의 classification_report 사용을 위해 삭제하지 말자!\n",
    "# del t_data_train\n",
    "# del t_data_test\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([784,10]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([10]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit)  # softmax activation function\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                 labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-1).minimize(loss)\n",
    "\n",
    "\n",
    "# parameter\n",
    "num_of_epoch = 1000\n",
    "batch_size = 100\n",
    "\n",
    "# 학습용 함수\n",
    "def run_train(sess,train_x, train_t):\n",
    "    print('### 학습 시작 ###')\n",
    "    # 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(num_of_epoch):\n",
    "        total_batch = int(train_x.shape[0] / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_t = train_t[i*batch_size:(i+1)*batch_size]           \n",
    "            _, loss_val = sess.run([train,loss],\n",
    "                                   feed_dict={X: batch_x,\n",
    "                                              T: batch_t})\n",
    "            \n",
    "        if step % 100 == 0:\n",
    "            print('Loss : {}'.format(loss_val))\n",
    "    print('### 학습 종료 ###')\n",
    "    \n",
    "# Accuracy 측정(정확도)    \n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(T,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "# 학습부터 해요!\n",
    "run_train(sess,x_data_train_norm, t_data_train_onehot)\n",
    "\n",
    "# Training Data Set을 이용하여 성능평가!\n",
    "print('### Training Data Set을 이용하여 성능평가!! ###')\n",
    "result = sess.run(accuracy, feed_dict={X:x_data_train_norm,\n",
    "                                       T:t_data_train_onehot})\n",
    "print('Accuracy : {}'.format(result))\n",
    "# Training Data Set을 이용하여 성능평가는 의미가 없어요!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우리의 모델의 성능평가를 하기 위해\n",
    "# K-Fold Cross Validation을 수행!\n",
    "\n",
    "cv = 5          # Fold의 수\n",
    "results = []    # 각 Fold당 학습과 성능평가가 진행되는데 \n",
    "                # 이때 계산된 성능평가 값을 저장\n",
    "kf = KFold(n_splits=cv, shuffle=True) \n",
    "\n",
    "for training_idx, validation_idx in kf.split(x_data_train_norm):\n",
    "    training_x = x_data_train_norm[training_idx] # Fancy indexing\n",
    "    training_t = t_data_train_onehot[training_idx]\n",
    "    \n",
    "    val_x = x_data_train_norm[validation_idx]\n",
    "    val_t = t_data_train_onehot[validation_idx]\n",
    "    \n",
    "    # 학습부터 시켜야 해요!\n",
    "    run_train(sess,training_x,training_t)\n",
    "    results.append(sess.run(accuracy, feed_dict={X:val_x, T:val_t}))\n",
    "\n",
    "print('측정한 각각의 결과값 : {}'.format(results))\n",
    "print('최종 K-Fold 교차검증을 사용한 Accuracy : {}'.format(np.mean(results)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "run_train(sess,x_data_train_norm,t_data_train_onehot)\n",
    "final_accuracy = sess.run(accuracy, feed_dict={X:x_data_test_norm,\n",
    "                                               T:t_data_test_onehot})\n",
    "print('우리 Model의 최종 정확도는 : {}'.format(final_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 Precision, Recall, F1, Accuracy를 각각 구하고 싶으면?\n",
    "# 첫번째 인자로 정답이 들어가야 해요(one hot encoding이 안된형태)\n",
    "target_names=['num 0', 'num 1', 'num 2', 'num 3', 'num 4', 'num 5',\n",
    "              'num 6', 'num 7', 'num 8', 'num 9']\n",
    "print(\n",
    "classification_report(t_data_test,\n",
    "                     sess.run(predict, feed_dict={X:x_data_test_norm}),\n",
    "                     target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code로 confusion matrix를 출력해보아요!\n",
    "# 3개의 label(정답)이 있는 multinomial classification에 대해\n",
    "# 예측값을 넣어서 confusion matrix를 출력해 보아요!\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [2, 0, 2, 2, 0,1]\n",
    "y_pred = [0, 0, 2, 2, 0,2]\n",
    "\n",
    "print(confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "confusion_matrix(t_data_test,\n",
    "                     sess.run(predict, feed_dict={X:x_data_test_norm})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 이미지를 가지고 예측을 해 보아요!\n",
    "# 이게 어려워요! 이미지 처리를 해야해요!\n",
    "\n",
    "# 이미지를 하나 구해야 해요!\n",
    "# 구한 color 이미지를 grey 이미지로 변환 => opencv를 이용\n",
    "\n",
    "import numpy as np\n",
    "import cv2  \n",
    "from PIL import Image   # conda install Pillow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "my_img = cv2.imread('./data/mnist/digit/5.jpg', cv2.IMREAD_COLOR)\n",
    "print(my_img.shape)   # (198, 132, 3)\n",
    "im_grey = cv2.cvtColor(my_img, cv2.COLOR_BGR2GRAY)\n",
    "print(im_grey.shape)\n",
    "cv2.imwrite('./data/mnist/digit/5_grey.jpg', im_grey)\n",
    "\n",
    "# 흑백이미지 파일을 얻었어요!\n",
    "img = Image.open('./data/mnist/digit/5_grey.jpg')\n",
    "plt.imshow(img, cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "# 사이즈가 안 맞아요!\n",
    "pixel = np.array(img)\n",
    "print('이미지의 크기 : {}'.format(pixel.size))\n",
    "print('이미지의 shape : {}'.format(pixel.shape))\n",
    "\n",
    "resize_img = img.resize((28,28))\n",
    "plt.imshow(resize_img, cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
