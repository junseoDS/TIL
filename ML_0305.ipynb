{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W:[[-0.05427659]\n",
      " [ 0.00701545]\n",
      " [ 0.7620886 ]\n",
      " [-0.5049089 ]\n",
      " [ 0.23032819]], b:[-0.09035717]. loss:1.0398504734039307\n",
      "W:[[-0.4692406 ]\n",
      " [ 0.33104324]\n",
      " [ 0.38213354]\n",
      " [-0.31306675]\n",
      " [ 0.09335237]], b:[-0.20169176]. loss:0.6275464296340942\n",
      "W:[[-0.49284774]\n",
      " [ 0.64801925]\n",
      " [ 0.292542  ]\n",
      " [-0.12847602]\n",
      " [ 0.08080075]], b:[-0.16279681]. loss:0.5790870785713196\n",
      "W:[[-0.5086747 ]\n",
      " [ 0.91347855]\n",
      " [ 0.21454765]\n",
      " [ 0.00632551]\n",
      " [ 0.06273412]], b:[-0.1259916]. loss:0.5467506051063538\n",
      "W:[[-0.5213084 ]\n",
      " [ 1.1374252 ]\n",
      " [ 0.14749122]\n",
      " [ 0.10347669]\n",
      " [ 0.04543357]], b:[-0.0904434]. loss:0.5247446894645691\n",
      "W:[[-0.532125  ]\n",
      " [ 1.3277742 ]\n",
      " [ 0.09035727]\n",
      " [ 0.17330202]\n",
      " [ 0.02952874]], b:[-0.05565356]. loss:0.509380042552948\n",
      "W:[[-0.54266655]\n",
      " [ 1.4909816 ]\n",
      " [ 0.04209569]\n",
      " [ 0.22368465]\n",
      " [ 0.01511404]], b:[-0.02115936]. loss:0.49835121631622314\n",
      "W:[[-5.5229437e-01]\n",
      " [ 1.6317717e+00]\n",
      " [ 7.4413756e-04]\n",
      " [ 2.6011181e-01]\n",
      " [ 1.7917494e-03]], b:[0.01287812]. loss:0.49023911356925964\n",
      "W:[[-0.5614085 ]\n",
      " [ 1.7538497 ]\n",
      " [-0.03504533]\n",
      " [ 0.28649503]\n",
      " [-0.01048371]], b:[0.04644912]. loss:0.48414334654808044\n",
      "W:[[-0.57035184]\n",
      " [ 1.8603727 ]\n",
      " [-0.06620047]\n",
      " [ 0.3056908 ]\n",
      " [-0.02171943]], b:[0.07961402]. loss:0.4794687330722809\n"
     ]
    }
   ],
   "source": [
    "# Titanic 구현\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('data/titanic/train.csv')\n",
    "\n",
    "# 학습에 필요하지 않은 column은 삭제할 꺼예요!\n",
    "df.drop(['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin'], \n",
    "        axis=1, \n",
    "        inplace=True)\n",
    "# display(df)\n",
    "\n",
    "# 성별처리\n",
    "gender_mapping = {'male': 0, 'female': 1}\n",
    "df['Sex'] = df['Sex'].map(gender_mapping)\n",
    "\n",
    "# 가족처리\n",
    "df['Family'] = df['SibSp'] + df['Parch']\n",
    "df.drop(['SibSp', 'Parch'], axis=1, inplace=True)\n",
    "# display(df)\n",
    "\n",
    "# 결측치 처리\n",
    "# df.isnull().sum()\n",
    "# Embarked 결측치 처리\n",
    "df['Embarked'] = df['Embarked'].fillna('Q')\n",
    "# Embarked 문자를 숫자로 변환\n",
    "embarked_mapping = {'S': 0, 'C': 1, 'Q':2 }\n",
    "df['Embarked'] = df['Embarked'].map(embarked_mapping)\n",
    "\n",
    "# Age 결측치 처리\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "# Age Binning 처리(Numerical value -> Categorical value)\n",
    "df.loc[df['Age'] < 8,'Age'] = 0\n",
    "df.loc[(df['Age'] >= 8) & (df['Age'] < 20),'Age'] = 1\n",
    "df.loc[(df['Age'] >= 20) & (df['Age'] < 65),'Age'] = 2\n",
    "df.loc[df['Age'] >= 65,'Age'] = 3\n",
    "\n",
    "# display(df.shape)\n",
    "\n",
    "# 학습과 validation을 수행해야 해요!\n",
    "# 데이터를 7:3 비율로 Training Data Set과 Validation Data Set으로 분리\n",
    "train_data = df.iloc[:int(df.shape[0] * 0.7)]\n",
    "val_data = df.iloc[int(df.shape[0] * 0.7):]\n",
    "\n",
    "# Training Data Set\n",
    "train_x_data = train_data.drop(['Survived'], axis=1, inplace=False).values\n",
    "train_t_data = train_data['Survived'].values.reshape(-1,1)\n",
    "\n",
    "# Validation Data Set\n",
    "val_x_data = val_data.drop(['Survived'], axis=1, inplace=False).values\n",
    "val_t_data = val_data['Survived'].values.reshape(-1,1)\n",
    "\n",
    "#######################\n",
    "\n",
    "# Tensorflow 구현\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,5], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weigth & bias\n",
    "W = tf.Variable(tf.random.normal([5,1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                              labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "\n",
    "# session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(300000):\n",
    "    _, W_val, b_val, loss_val = sess.run([train,W,b,loss], \n",
    "                                         feed_dict={X: train_x_data,\n",
    "                                                    T: train_t_data})\n",
    "    if step % 30000 == 0:\n",
    "        print('W:{}, b:{}. loss:{}'.format(W_val,b_val,loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 정확도 : 0.7947761416435242\n"
     ]
    }
   ],
   "source": [
    "# 정확도(Accuracy) 측정\n",
    "predict = tf.cast(H > 0.5, dtype=tf.float32)  # 예측값 : [1 0 0 0 1 0 1 0]\n",
    "correct = tf.equal(predict, T) # T : [1 1 0 0 ..]   =>  [True, False, ...]  \n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "accuracy_val = sess.run(accuracy, feed_dict={X:val_x_data,\n",
    "                                             T:val_t_data})\n",
    "print('모델의 정확도 : {}'.format(accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bmi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Classification\n",
    "# %reset\n",
    "\n",
    "# Tensorflow로 구현해 보아요!\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('data/bmi.csv')\n",
    "\n",
    "# display(df.head(), df.shape)\n",
    "\n",
    "### 결측치 처리 ###\n",
    "# df.isnull().sum()   # 결측치가 존재하지 않아요!\n",
    "\n",
    "### 이상치 처리 ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['label']=='thin']=0\n",
    "df[df['label']=='normal']=1\n",
    "df[df['label']=='fat']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        2\n",
       "2        0\n",
       "3        2\n",
       "4        1\n",
       "        ..\n",
       "19995    0\n",
       "19996    2\n",
       "19997    1\n",
       "19998    1\n",
       "19999    1\n",
       "Name: label, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig_1 = fig.add_subplot(1,3,1)\n",
    "fig_2 = fig.add_subplot(1,3,2)\n",
    "fig_3 = fig.add_subplot(1,3,3)\n",
    "\n",
    "fig_1.boxplot(df['label'])\n",
    "fig_2.boxplot(df['height'])\n",
    "fig_3.boxplot(df['weight'])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### boxplot을 이용해서 이상치가 존재하는지를 확인해요!!\n",
    "### 이상치는 현재 존재하지 않아요!\n",
    "\n",
    "### Training Data Set\n",
    "x_data = df[['height', 'weight']].values\n",
    "t_data = df['label'].values  # one hot encoding으로 변환\n",
    "###      [0 1 2 0 1 1 2 2 0 1]\n",
    "###      [[1 0 0]\n",
    "###       [0 1 0]\n",
    "###       [0 0 1]\n",
    "###       [1 0 0]]\n",
    "\n",
    "### 정규화\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(x_data)\n",
    "norm_x_data = scaler_x.transform(x_data)\n",
    "# print(norm_x_data)\n",
    "\n",
    "### tensorflow 기능을 이용해서 one hot encoding을 생성\n",
    "sess = tf.Session()\n",
    "norm_t_data = sess.run(tf.one_hot(t_data, depth=3))\n",
    "# print(norm_t_data)\n",
    "\n",
    "## training data set 준비 끝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W : [[-0.74057055  0.46742615  0.05792918]\n",
      " [-0.08616608 -1.0153077   1.6942377 ]], b: [ 0.39123935 -1.5441076  -2.505711  ], loss: 1.0482169389724731\n",
      "W : [[-0.82522815  0.4930965   0.11691654]\n",
      " [-0.17082392 -0.98963755  1.7532248 ]], b: [ 0.2929184 -1.4928261 -2.458673 ], loss: 0.9241164326667786\n",
      "W : [[-0.8967902   0.5161728   0.16540267]\n",
      " [-0.2423862  -0.9665612   1.8017111 ]], b: [ 0.21211253 -1.4466234  -2.4240723 ], loss: 0.8376342058181763\n",
      "W : [[-0.9580207   0.5371062   0.20569955]\n",
      " [-0.30361676 -0.9456278   1.842008  ]], b: [ 0.14560139 -1.4048605  -2.3993242 ], loss: 0.7761402130126953\n",
      "W : [[-1.0112319   0.5562318   0.23978521]\n",
      " [-0.3568274  -0.9265022   1.8760931 ]], b: [ 0.090605  -1.3670045 -2.3821762], loss: 0.7311422824859619\n",
      "W : [[-1.0581918   0.5737859   0.26919106]\n",
      " [-0.40378878 -0.9089481   1.9054986 ]], b: [ 0.04491573 -1.33263    -2.370861  ], loss: 0.6972441077232361\n",
      "W : [[-1.1002243   0.58995014  0.29505748]\n",
      " [-0.44581935 -0.8927839   1.9313651 ]], b: [ 0.00682436 -1.3013923  -2.364022  ], loss: 0.6709810495376587\n",
      "W : [[-1.1383033   0.6048615   0.31822595]\n",
      " [-0.48389915 -0.8778725   1.9545355 ]], b: [-0.02499109 -1.2729871  -2.3606083 ], loss: 0.6501259803771973\n",
      "W : [[-1.173171    0.6186371   0.3393146 ]\n",
      " [-0.5187636  -0.86409694  1.9756286 ]], b: [-0.05156371 -1.2471584  -2.3598516 ], loss: 0.6331892609596252\n",
      "W : [[-1.2053777   0.6313814   0.3587843 ]\n",
      " [-0.55097526 -0.85135263  1.9950995 ]], b: [-0.07371183 -1.2236602  -2.361225  ], loss: 0.6191688179969788\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## tensorflow 구현\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([2,3]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([3]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit)   # Softmax Activation function 이용\n",
    "\n",
    "# loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                 labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "\n",
    "# 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습진행\n",
    "for step in range(30000):\n",
    "    _, W_val, b_val, loss_val = sess.run([train,W,b,loss], \n",
    "                                         feed_dict={X:norm_x_data,\n",
    "                                                    T:norm_t_data})\n",
    "    if step % 3000 == 0:\n",
    "        print('W : {}, b: {}, loss: {}'.format(W_val, b_val, loss_val))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000000e+00 9.861656e-38 1.000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# 잘 만들어진 모델인지 확인하고 넘어가야 해요!(train, validation)\n",
    "\n",
    "# prediction\n",
    "height = 187\n",
    "weight = 78\n",
    "my_state = [[height, weight]]\n",
    "\n",
    "result = sess.run(H, feed_dict={X:scaler_x.transform(my_state)})\n",
    "print(result)  # 2 => 과체중 ?? 확인을 해 봐야 해요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
