{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fewer-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ozone data를 이용한 Tensorflow 2.x Linear Regression 구현\n",
    "\n",
    "# Data 전처리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')   # warning 출력을 하지 않아요!\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('./ozone.csv')\n",
    "# display(df.head(), df.shape)\n",
    "\n",
    "# 독립변수 & 종속변수\n",
    "x_data = df[['Solar.R', 'Wind', 'Temp']]  # Fancy indexing\n",
    "t_data = df['Ozone']\n",
    "\n",
    "# 1. 독립변수에 대한 결측치를 검출한 후 Imputation을 진행(평균화기법-median)\n",
    "#    median으로 처리하는 이유는 이상치를 처리하지 않았기 때문.\n",
    "for col in x_data.columns:\n",
    "    col_median = np.nanmedian(x_data[col])\n",
    "    x_data[col].loc[x_data[col].isnull()] = col_median\n",
    "    \n",
    "# 2. 독립변수에 대한 이상치를 검출한 후 mean값으로 처리할께요!\n",
    "zscore_threshold = 1.8   # z-score outlier 임계값으로 사용\n",
    "\n",
    "for col in x_data.columns:\n",
    "    outlier = x_data[col][(np.abs(stats.zscore(x_data[col])) > zscore_threshold)]\n",
    "    col_mean = np.mean(x_data.loc[~x_data[col].isin(outlier),col])\n",
    "    x_data.loc[x_data[col].isin(outlier),col] = col_mean\n",
    "    \n",
    "# 3. 종속변수에 대한 이상치를 검출 한 후 mean값으로 처리할께요!     \n",
    "outlier = t_data[(np.abs(stats.zscore(t_data)) > zscore_threshold)]\n",
    "col_mean = np.mean(t_data[~t_data.isin(outlier)])\n",
    "t_data[t_data.isin(outlier)] = col_mean\n",
    "\n",
    "# 4. 정규화\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_t = MinMaxScaler()\n",
    "\n",
    "scaler_x.fit(x_data.values)\n",
    "scaler_t.fit(t_data.values.reshape(-1,1))\n",
    "\n",
    "x_data_norm = scaler_x.transform(x_data.values)\n",
    "t_data_norm = scaler_t.transform(t_data.values.reshape(-1,1)).ravel()\n",
    "\n",
    "# 5. 종속변수에 대한 결측치를 KNN을 이용하여 Imputation 처리\n",
    "# KNN 학습에 사용될 x_data와 t_data를 추려내야 해요!\n",
    "x_data_train_norm = x_data_norm[~np.isnan(t_data_norm)]\n",
    "t_data_train_norm = t_data_norm[~np.isnan(t_data_norm)]\n",
    "\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=2)\n",
    "knn_regressor.fit(x_data_train_norm,t_data_train_norm)\n",
    "\n",
    "knn_predict = knn_regressor.predict(x_data_norm[np.isnan(t_data_norm)])\n",
    "t_data_norm[np.isnan(t_data_norm)] = knn_predict\n",
    "\n",
    "## 최종적으로 얻은 데이터\n",
    "## 독립변수 :  x_data_norm\n",
    "## 종속변수 : t_data_norm\n",
    "\n",
    "## 이 데이터를 이용해서 sklearn과 tensorflow 2.x로 구현을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "herbal-cooling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn의 결과 : [[38.75927452]]\n",
      "keras의 결과 : [[38.752106]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "test_data = [[310, 15, 80]]  # 모델 생성 후 prediction할 데이터!\n",
    "\n",
    "# sklearn\n",
    "model = LinearRegression()\n",
    "model.fit(x_data_norm,t_data_norm)\n",
    "result = model.predict(scaler_x.transform(test_data))\n",
    "print('sklearn의 결과 : {}'.format(scaler_t.inverse_transform(result.reshape(-1,1))))\n",
    "\n",
    "# tensorflow 2.x 구현\n",
    "keras_model = Sequential()\n",
    "\n",
    "keras_model.add(Flatten(input_shape=(3,)))\n",
    "keras_model.add(Dense(1, activation='linear'))\n",
    "\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-2), loss='mse')\n",
    "\n",
    "keras_model.fit(x_data_norm,\n",
    "                t_data_norm,\n",
    "                epochs=5000,\n",
    "                verbose=0)\n",
    "\n",
    "keras_result = keras_model.predict(scaler_x.transform(test_data))\n",
    "\n",
    "print('keras의 결과 : {}'.format(scaler_t.inverse_transform(keras_result.reshape(-1,1))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "imposed-excitement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex  Age  Embarked  Family\n",
       "0           0       3    0    0       0.0       1\n",
       "1           1       1    1    1       1.0       1\n",
       "2           1       3    1    1       0.0       0\n",
       "3           1       1    1    1       0.0       1\n",
       "4           0       3    0    1       0.0       0\n",
       "..        ...     ...  ...  ...       ...     ...\n",
       "886         0       2    0    1       0.0       0\n",
       "887         1       1    1    0       0.0       0\n",
       "888         0       3    1    1       0.0       3\n",
       "889         1       1    0    1       1.0       0\n",
       "890         0       3    0    1       2.0       0\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn의 accuracy : 0.7947761194029851\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4481 - accuracy: 0.7948\n",
      "keras의 accuracy : [0.44806188344955444, 0.7947761416435242]\n"
     ]
    }
   ],
   "source": [
    "# Titanic 예제를 이용해서 \n",
    "# sklearn으로 구현해서 accuracy를 측정하고\n",
    "# tensorflow 2.x버전으로 구현해서 accuracy를 측정해 보아요!\n",
    "# Logistic Regression을 이용해서 Binary classification을 수행!\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import stats\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('./data/titanic/train.csv')\n",
    "# display(df)\n",
    "# Feature Engineering\n",
    "\n",
    "# 필요없는 column은 삭제\n",
    "df = df.drop(['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin'],\n",
    "            axis=1, inplace=False)\n",
    "# display(df)\n",
    "df['Family'] = df['SibSp'] + df['Parch']\n",
    "df.drop(['SibSp','Parch'], axis=1, inplace=True)\n",
    "# display(df)\n",
    "\n",
    "sex_dict = {'male': 0, 'female': 1}\n",
    "df['Sex'] = df['Sex'].map(sex_dict)\n",
    "\n",
    "embarked_dict = {'S':0, 'C':1, 'Q':2}\n",
    "df['Embarked'] = df['Embarked'].map(embarked_dict)\n",
    "\n",
    "# display(df)\n",
    "\n",
    "# 결측치 처리\n",
    "# 'Age'에 결측치가 존재, 'Embarked'에도 결측치가 있어요!\n",
    "# 'Age'는 median으로 'Embarked'는 최빈값(mode)로 결측치 처리\n",
    "df.loc[df['Age'].isnull(),'Age'] = np.nanmedian(df['Age'].values)\n",
    "# print(stats.mode(df['Embarked'], nan_policy='omit')[0])\n",
    "df.loc[df['Embarked'].isnull(),'Embarked'] = 0\n",
    "# 이상치 처리\n",
    "# 실 데이터이기 때문에 이상치 처리는 하지 않을께요!\n",
    "\n",
    "# Age를 categorical value로 변경해서 사용해요!\n",
    "def age_category(age):\n",
    "    if (age >= 0) & (age < 25):\n",
    "        return 0\n",
    "    elif (age >= 25) & (age < 50):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "df['Age'] = df['Age'].map(age_category)    \n",
    "\n",
    "display(df)\n",
    "\n",
    "# train test split\n",
    "\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(df.drop('Survived', axis=1, inplace=False),\n",
    "                 df['Survived'],\n",
    "                 test_size=0.3,\n",
    "                 random_state=0)\n",
    "\n",
    "# 정규화\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data_train)\n",
    "\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "\n",
    "###########################\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_data_train_norm, t_data_train)\n",
    "result = model.score(x_data_test_norm, t_data_test)\n",
    "print('sklearn의 accuracy : {}'.format(result))  # 0.7947761194029851\n",
    "\n",
    "\n",
    "###########################\n",
    "\n",
    "keras_model = Sequential()\n",
    "\n",
    "keras_model.add(Flatten(input_shape=(x_data_train_norm.shape[1],)))\n",
    "keras_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-2),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "keras_model.fit(x_data_train_norm,\n",
    "                t_data_train,\n",
    "                epochs=1000,\n",
    "                verbose=0)\n",
    "\n",
    "keras_result = keras_model.evaluate(x_data_test_norm, t_data_test)\n",
    "print('keras의 accuracy : {}'.format(keras_result))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env_tf2] *",
   "language": "python",
   "name": "conda-env-data_env_tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
